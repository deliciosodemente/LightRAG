@echo off
setlocal enabledelayedexpansion

:: Colors for Windows CMD (limited support)
:: Using simple text for Windows compatibility

echo [INFO] LightRAG Local Configuration Setup
echo ========================================
echo.

:: Default values
set "LIGHTRAG_API_KEY=dev-api-key-%date:~10,4%%date:~4,2%%date:~7,2%%time:~0,2%%time:~3,2%%time:~6,2%"
set "PORT=9621"
set "WORKERS=2"
set "LLM_CHOICE=1"
set "USE_CLOUDFLARE=true"
set "LLM_BINDING=openai"
set "LLM_MODEL=gpt-4o-mini"
set "EMBEDDING_BINDING=openai"
set "EMBEDDING_MODEL=text-embedding-3-small"
set "EMBEDDING_DIM=1536"

echo [INFO] Configuring basic LightRAG settings...
echo.

:: Get user input for API key
set /p "LIGHTRAG_API_KEY=Enter LightRAG API Key [%LIGHTRAG_API_KEY%]: "
if "%LIGHTRAG_API_KEY%"=="" set "LIGHTRAG_API_KEY=dev-api-key-%date:~10,4%%date:~4,2%%date:~7,2%%time:~0,2%%time:~3,2%%time:~6,2%"

:: Get user input for port
set /p "PORT=Enter server port [%PORT%]: "
if "%PORT%"=="" set "PORT=9621"

:: Get user input for workers
set /p "WORKERS=Enter number of workers [%WORKERS%]: "
if "%WORKERS%"=="" set "WORKERS=2"

echo.
echo [INFO] Configuring LLM settings...
echo.
echo LLM Options:
echo 1. OpenAI (with Cloudflare Gateway)
echo 2. OpenAI (direct)
echo 3. Ollama (local)
echo 4. Other
echo.

:: Get LLM choice
set /p "LLM_CHOICE=Choose LLM provider (1-4) [%LLM_CHOICE%]: "
if "%LLM_CHOICE%"=="" set "LLM_CHOICE=1"

:: Configure based on choice
if "%LLM_CHOICE%"=="1" (
    set "LLM_BINDING=openai"
    set "LLM_MODEL=gpt-4o-mini"
    set "USE_CLOUDFLARE=true"
    set "EMBEDDING_BINDING=openai"
    set "EMBEDDING_MODEL=text-embedding-3-small"
    set "EMBEDDING_DIM=1536"
) else if "%LLM_CHOICE%"=="2" (
    set "LLM_BINDING=openai"
    set "LLM_MODEL=gpt-4o-mini"
    set "USE_CLOUDFLARE=false"
    set "EMBEDDING_BINDING=openai"
    set "EMBEDDING_MODEL=text-embedding-3-small"
    set "EMBEDDING_DIM=1536"
) else if "%LLM_CHOICE%"=="3" (
    set "LLM_BINDING=ollama"
    set "LLM_MODEL=mistral"
    set "USE_CLOUDFLARE=false"
    set "EMBEDDING_BINDING=ollama"
    set "EMBEDDING_MODEL=bge-m3"
    set "EMBEDDING_DIM=1024"
) else (
    set /p "LLM_BINDING=Enter LLM binding [%LLM_BINDING%]: "
    if "!LLM_BINDING!"=="" set "LLM_BINDING=openai"
    set /p "LLM_MODEL=Enter LLM model [%LLM_MODEL%]: "
    if "!LLM_MODEL!"=="" set "LLM_MODEL=gpt-4o-mini"
    set "USE_CLOUDFLARE=false"
)

:: Cloudflare configuration
if "%USE_CLOUDFLARE%"=="true" (
    echo.
    echo [INFO] Cloudflare AI Gateway Configuration
    echo ==========================================
    echo.
    echo You'll need to run the Cloudflare setup script first:
    echo   .\setup-cloudflare.bat
    echo.
    echo For now, we'll set placeholder values that you can update later.
    echo.
    set "CLOUDFLARE_ACCOUNT_ID=your-cloudflare-account-id"
    set "CLOUDFLARE_GATEWAY_ID=your-gateway-id"
    set "CLOUDFLARE_API_KEY=your-cloudflare-api-key"
)

:: Create .env.local file
echo.
echo [INFO] Creating .env.local file...
echo.

:: Create the environment file
(
echo ### Local Development Environment Configuration for LightRAG
echo ### Generated by configure-local.bat on %date% %time%
echo.
echo ###########################
echo ### Server Configuration
echo ###########################
echo HOST=0.0.0.0
echo PORT=%PORT%
echo WORKERS=%WORKERS%
echo WEBUI_TITLE='LightRAG Local Development'
echo WEBUI_DESCRIPTION="Local Development Environment"
echo.
echo ### Directory Configuration
echo WORKING_DIR=/app/data/rag_storage
echo INPUT_DIR=/app/data/inputs
echo LOG_DIR=/app/logs
echo.
echo ### Logging
echo LOG_LEVEL=DEBUG
echo VERBOSE=true
echo.
echo #####################################
echo ### Authentication and Security
echo #####################################
echo LIGHTRAG_API_KEY=%LIGHTRAG_API_KEY%
echo WHITELIST_PATHS=/health,/api/docs,/api/redoc
echo.
echo ######################################################################################
echo ### Query Configuration
echo ######################################################################################
echo ENABLE_LLM_CACHE=true
echo TOP_K=40
echo CHUNK_TOP_K=20
echo MAX_ENTITY_TOKENS=6000
echo MAX_RELATION_TOKENS=8000
echo MAX_TOTAL_TOKENS=30000
echo RELATED_CHUNK_NUMBER=5
echo KG_CHUNK_PICK_METHOD=VECTOR
echo.
echo ###############################
echo ### Concurrency Configuration
echo ###############################
echo MAX_ASYNC=4
echo MAX_PARALLEL_INSERT=2
echo EMBEDDING_FUNC_MAX_ASYNC=8
echo EMBEDDING_BATCH_NUM=10
echo.
echo ###########################################################
echo ### Cloudflare AI Gateway Integration
echo ###########################################################
echo USE_CLOUDFLARE_GATEWAY=%USE_CLOUDFLARE%
echo CLOUDFLARE_ACCOUNT_ID=%CLOUDFLARE_ACCOUNT_ID%
echo CLOUDFLARE_GATEWAY_ID=%CLOUDFLARE_GATEWAY_ID%
echo CLOUDFLARE_API_KEY=%CLOUDFLARE_API_KEY%
echo.
echo ### LLM Configuration
echo LLM_BINDING=%LLM_BINDING%
echo LLM_MODEL=%LLM_MODEL%
) > .env.local

:: Add API key configuration based on Cloudflare usage
if "%USE_CLOUDFLARE%"=="true" (
    echo LLM_BINDING_API_KEY=${CLOUDFLARE_API_KEY}>> .env.local
) else (
    echo LLM_BINDING_API_KEY=your-openai-api-key>> .env.local
)

:: Continue with the rest of the configuration
(
echo.
echo ### OpenAI-specific settings
echo OPENAI_LLM_MAX_TOKENS=8000
echo OPENAI_LLM_MAX_COMPLETION_TOKENS=8000
echo.
echo ####################################################################################
echo ### Embedding Configuration
echo ####################################################################################
echo EMBEDDING_BINDING=%EMBEDDING_BINDING%
echo EMBEDDING_MODEL=%EMBEDDING_MODEL%
echo EMBEDDING_DIM=%EMBEDDING_DIM%
) >> .env.local

:: Add embedding API key
if "%USE_CLOUDFLARE%"=="true" (
    echo EMBEDDING_BINDING_API_KEY=${CLOUDFLARE_API_KEY}>> .env.local
) else (
    echo EMBEDDING_BINDING_API_KEY=your-openai-embedding-key>> .env.local
)

:: Continue with remaining configuration
(
echo.
echo ########################################
echo ### Document Processing Configuration
echo ########################################
echo ENABLE_LLM_CACHE_FOR_EXTRACT=true
echo SUMMARY_LANGUAGE=English
echo CHUNK_SIZE=1200
echo CHUNK_OVERLAP_SIZE=100
echo MAX_PARALLEL_INSERT=2
echo FORCE_LLM_SUMMARY_ON_MERGE=8
echo SUMMARY_MAX_TOKENS=1200
echo SUMMARY_LENGTH_RECOMMENDED=600
echo SUMMARY_CONTEXT_SIZE=12000
echo.
echo ############################
echo ### Data Storage Selection (Local)
echo ############################
echo LIGHTRAG_KV_STORAGE=JsonKVStorage
echo LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage
echo LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
echo LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage
echo.
echo WORKSPACE=local-dev
echo TIKTOKEN_CACHE_DIR=/app/temp/tiktoken
) >> .env.local

echo [SUCCESS] Environment file .env.local created successfully!
echo.
echo [INFO] Next steps:
echo.

if "%USE_CLOUDFLARE%"=="true" (
    echo 1. Setup Cloudflare AI Gateway:
    echo    .\setup-cloudflare.bat
    echo.
    echo 2. Update API keys in .env.local:
    echo    - CLOUDFLARE_API_KEY
    echo    - OpenAI API keys (if needed)
    echo.
) else (
    echo 1. Add your API keys to .env.local:
    if "%LLM_BINDING%"=="openai" (
        echo    - LLM_BINDING_API_KEY
        echo    - EMBEDDING_BINDING_API_KEY
    )
    echo.
)

echo 2. Deploy LightRAG:
echo    .\deploy.bat deploy .env.local
echo.
echo 3. Access your application:
echo    - Web UI: http://localhost:%PORT%
echo    - API Docs: http://localhost:%PORT%/docs
echo.

pause