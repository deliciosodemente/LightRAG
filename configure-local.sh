#!/bin/bash

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Function to prompt for input with default
prompt_with_default() {
    local prompt="$1"
    local default="$2"
    local response

    read -p "$prompt [$default]: " response
    echo "${response:-$default}"
}

# Function to configure basic settings
configure_basic() {
    print_info "Configuring basic LightRAG settings..."

    # API Key
    LIGHTRAG_API_KEY=$(prompt_with_default "Enter LightRAG API Key" "dev-api-key-$(date +%s)")

    # Port
    PORT=$(prompt_with_default "Enter server port" "9621")

    # Workers
    WORKERS=$(prompt_with_default "Enter number of workers" "2")

    print_success "Basic configuration completed"
}

# Function to configure LLM settings
configure_llm() {
    print_info "Configuring LLM settings..."

    echo "LLM Options:"
    echo "1. OpenAI (with Cloudflare Gateway)"
    echo "2. OpenAI (direct)"
    echo "3. Ollama (local)"
    echo "4. Other"

    LLM_CHOICE=$(prompt_with_default "Choose LLM provider (1-4)" "1")

    case $LLM_CHOICE in
        1)
            LLM_BINDING="openai"
            LLM_MODEL=$(prompt_with_default "Enter OpenAI model" "gpt-4o-mini")
            USE_CLOUDFLARE="true"
            ;;
        2)
            LLM_BINDING="openai"
            LLM_MODEL=$(prompt_with_default "Enter OpenAI model" "gpt-4o-mini")
            USE_CLOUDFLARE="false"
            ;;
        3)
            LLM_BINDING="ollama"
            LLM_MODEL=$(prompt_with_default "Enter Ollama model" "mistral")
            EMBEDDING_BINDING="ollama"
            EMBEDDING_MODEL=$(prompt_with_default "Enter embedding model" "bge-m3")
            USE_CLOUDFLARE="false"
            ;;
        *)
            LLM_BINDING=$(prompt_with_default "Enter LLM binding" "openai")
            LLM_MODEL=$(prompt_with_default "Enter LLM model" "gpt-4o-mini")
            USE_CLOUDFLARE="false"
            ;;
    esac

    print_success "LLM configuration completed"
}

# Function to configure Cloudflare (if selected)
configure_cloudflare() {
    if [ "$USE_CLOUDFLARE" = "true" ]; then
        print_info "Configuring Cloudflare AI Gateway..."

        echo ""
        print_warning "You'll need to run the Cloudflare setup script first:"
        echo "  ./setup-cloudflare.sh"
        echo ""
        echo "For now, we'll set placeholder values that you can update later."
        echo ""

        CLOUDFLARE_ACCOUNT_ID="your-cloudflare-account-id"
        CLOUDFLARE_GATEWAY_ID="your-gateway-id"
        CLOUDFLARE_API_KEY="your-cloudflare-api-key"
    fi
}

# Function to configure embeddings
configure_embeddings() {
    if [ "$EMBEDDING_BINDING" != "ollama" ]; then
        print_info "Configuring embeddings..."

        EMBEDDING_BINDING=$(prompt_with_default "Enter embedding binding" "openai")
        EMBEDDING_MODEL=$(prompt_with_default "Enter embedding model" "text-embedding-3-small")
        EMBEDDING_DIM=$(prompt_with_default "Enter embedding dimensions" "1536")
    fi
}

# Function to update environment file
update_env_file() {
    local env_file="$1"

    print_info "Updating environment file: $env_file"

    # Create backup
    if [ -f "$env_file" ]; then
        cp "$env_file" "${env_file}.backup.$(date +%Y%m%d_%H%M%S)"
        print_info "Backup created"
    fi

    # Update the environment file
    cat > "$env_file" << EOF
### Local Development Environment Configuration for LightRAG
### Generated by configure-local.sh on $(date)

###########################
### Server Configuration
###########################
HOST=0.0.0.0
PORT=$PORT
WORKERS=$WORKERS
WEBUI_TITLE='LightRAG Local Development'
WEBUI_DESCRIPTION="Local Development Environment"

### Directory Configuration
WORKING_DIR=/app/data/rag_storage
INPUT_DIR=/app/data/inputs
LOG_DIR=/app/logs

### Logging
LOG_LEVEL=DEBUG
VERBOSE=true

#####################################
### Authentication and Security
#####################################
LIGHTRAG_API_KEY=$LIGHTRAG_API_KEY
WHITELIST_PATHS=/health,/api/docs,/api/redoc

######################################################################################
### Query Configuration
######################################################################################
ENABLE_LLM_CACHE=true
TOP_K=40
CHUNK_TOP_K=20
MAX_ENTITY_TOKENS=6000
MAX_RELATION_TOKENS=8000
MAX_TOTAL_TOKENS=30000
RELATED_CHUNK_NUMBER=5
KG_CHUNK_PICK_METHOD=VECTOR

###############################
### Concurrency Configuration
###############################
MAX_ASYNC=4
MAX_PARALLEL_INSERT=2
EMBEDDING_FUNC_MAX_ASYNC=8
EMBEDDING_BATCH_NUM=10

###########################################################
### Cloudflare AI Gateway Integration
###########################################################
USE_CLOUDFLARE_GATEWAY=$USE_CLOUDFLARE
CLOUDFLARE_ACCOUNT_ID=$CLOUDFLARE_ACCOUNT_ID
CLOUDFLARE_GATEWAY_ID=$CLOUDFLARE_GATEWAY_ID
CLOUDFLARE_API_KEY=$CLOUDFLARE_API_KEY

### LLM Configuration
LLM_BINDING=$LLM_BINDING
LLM_MODEL=$LLM_MODEL
EOF

    # Add Cloudflare-specific configuration
    if [ "$USE_CLOUDFLARE" = "true" ]; then
        cat >> "$env_file" << EOF
LLM_BINDING_API_KEY=\${CLOUDFLARE_API_KEY}
EOF
    else
        cat >> "$env_file" << EOF
LLM_BINDING_API_KEY=your-openai-api-key
EOF
    fi

    cat >> "$env_file" << EOF

### OpenAI-specific settings
OPENAI_LLM_MAX_TOKENS=8000
OPENAI_LLM_MAX_COMPLETION_TOKENS=8000

####################################################################################
### Embedding Configuration
####################################################################################
EMBEDDING_BINDING=$EMBEDDING_BINDING
EMBEDDING_MODEL=$EMBEDDING_MODEL
EMBEDDING_DIM=$EMBEDDING_DIM
EOF

    if [ "$USE_CLOUDFLARE" = "true" ]; then
        cat >> "$env_file" << EOF
EMBEDDING_BINDING_API_KEY=\${CLOUDFLARE_API_KEY}
EOF
    else
        cat >> "$env_file" << EOF
EMBEDDING_BINDING_API_KEY=your-openai-embedding-key
EOF
    fi

    cat >> "$env_file" << EOF

########################################
### Document Processing Configuration
########################################
ENABLE_LLM_CACHE_FOR_EXTRACT=true
SUMMARY_LANGUAGE=English
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100
MAX_PARALLEL_INSERT=2
FORCE_LLM_SUMMARY_ON_MERGE=8
SUMMARY_MAX_TOKENS=1200
SUMMARY_LENGTH_RECOMMENDED=600
SUMMARY_CONTEXT_SIZE=12000

############################
### Data Storage Selection (Local)
############################
LIGHTRAG_KV_STORAGE=JsonKVStorage
LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage
LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage

WORKSPACE=local-dev
TIKTOKEN_CACHE_DIR=/app/temp/tiktoken
EOF

    print_success "Environment file updated successfully"
}

# Function to show next steps
show_next_steps() {
    echo ""
    print_success "Configuration completed!"
    echo ""
    print_info "Next steps:"
    echo ""

    if [ "$USE_CLOUDFLARE" = "true" ]; then
        echo "1. 🚀 Set up Cloudflare AI Gateway:"
        echo "   ./setup-cloudflare.sh"
        echo ""
        echo "2. 🔑 Update API keys in .env.local:"
        echo "   - CLOUDFLARE_API_KEY"
        echo "   - OpenAI API keys (if needed)"
        echo ""
    else
        echo "1. 🔑 Add your API keys to .env.local:"
        if [ "$LLM_BINDING" = "openai" ]; then
            echo "   - LLM_BINDING_API_KEY"
            echo "   - EMBEDDING_BINDING_API_KEY"
        fi
        echo ""
    fi

    echo "3. 🚀 Deploy LightRAG:"
    echo "   ./deploy.sh deploy .env.local"
    echo ""
    echo "4. 🌐 Access your application:"
    echo "   - Web UI: http://localhost:$PORT"
    echo "   - API Docs: http://localhost:$PORT/docs"
    echo ""
}

# Main configuration function
configure_local() {
    local env_file="${1:-.env.local}"

    print_info "LightRAG Local Configuration Setup"
    echo "=================================="
    echo ""

    # Run configuration steps
    configure_basic
    configure_llm
    configure_cloudflare
    configure_embeddings
    update_env_file "$env_file"
    show_next_steps
}

# Function to show usage
usage() {
    cat << EOF
LightRAG Local Configuration Script

USAGE:
    $0 [ENV_FILE]

ARGUMENTS:
    ENV_FILE    Environment file to create/update (default: .env.local)

DESCRIPTION:
    This script helps you configure LightRAG for local development
    by interactively setting up environment variables.

EXAMPLES:
    $0              # Configure .env.local
    $0 .env.dev     # Configure custom environment file

EOF
}

# Main script logic
case "${1:-}" in
    -h|--help)
        usage
        ;;
    *)
        configure_local "${1:-.env.local}"
        ;;
esac